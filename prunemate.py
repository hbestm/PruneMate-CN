"""PruneMate - Dockerå®šæ—¶æ¸…ç†åŠ©æ‰‹

åŠŸèƒ½ç‰¹æ€§ï¼š
1. æ”¯æŒå®šæ—¶æ¸…ç†Dockerèµ„æº
2. å¯æ¸…ç†ï¼šå®¹å™¨ã€é•œåƒã€ç½‘ç»œã€å·ã€æ„å»ºç¼“å­˜
3. æ”¯æŒå¤šDockerä¸»æœº
4. é€šçŸ¥é›†æˆï¼šGotifyã€ntfyã€Discordã€Telegram
5. å†å²ç»Ÿè®¡ä¸é¢„è§ˆåŠŸèƒ½
"""

import os
import sys
import json
import logging
import tempfile
import datetime
import calendar
import base64
import urllib.request
import urllib.parse
from logging.handlers import RotatingFileHandler
from pathlib import Path

from flask import Flask, render_template, request, redirect, url_for, flash, jsonify, session, Response, make_response
from werkzeug.security import check_password_hash, generate_password_hash
from filelock import FileLock, Timeout
from gunicorn.app.base import BaseApplication
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from zoneinfo import ZoneInfo

# å¯é€‰Dockerå¯¼å…¥ï¼ˆæœ€ä½³å°è¯•ï¼‰
try:
    import docker
except Exception:
    docker = None

# Flaskåº”ç”¨åˆå§‹åŒ–
app = Flask(__name__)
app.secret_key = os.environ.get("PRUNEMATE_SECRET", "prunemate-secret-key")

# è·¯å¾„å’Œé»˜è®¤é…ç½®
CONFIG_PATH = Path(os.environ.get("PRUNEMATE_CONFIG", "/config/config.json"))
# æ–‡ä»¶é”ï¼šç¡®ä¿è·¨è¿›ç¨‹çš„æ¸…ç†ä»»åŠ¡ä¸ä¼šåŒæ—¶æ‰§è¡Œ
LOCK_FILE = Path(os.environ.get("PRUNEMATE_LOCK", "/config/prunemate.lock"))
# ç”¨äºè®°å½•ä¸Šæ¬¡è¿è¡Œæ—¶é—´çš„æ–‡ä»¶ï¼Œé˜²æ­¢å¤šWorkeré‡å¤æ‰§è¡Œ
LAST_RUN_FILE = Path(os.environ.get("PRUNEMATE_LAST_RUN", "/config/last_run_key"))
LAST_RUN_LOCK = Path(str(LAST_RUN_FILE) + ".lock")
# ç”¨äºä¿å­˜å†å²ç»Ÿè®¡æ•°æ®çš„æ–‡ä»¶
STATS_FILE = Path(os.environ.get("PRUNEMATE_STATS", "/config/stats.json"))

DEFAULT_CONFIG = {
    "schedule_enabled": True,
    "frequency": "daily",
    "time": "03:00",
    "day_of_week": "mon",
    "day_of_month": 1,
    "prune_containers": False,
    "prune_images": True,
    "prune_networks": False,
    "prune_volumes": False,
    "prune_build_cache": False,
    "docker_hosts": [],
    "notifications": {
        "provider": "gotify",
        "gotify": {"enabled": False, "url": "", "token": ""},
        "ntfy": {"enabled": False, "url": "", "topic": "", "token": ""},
        "discord": {"enabled": False, "webhook_url": ""},
        "telegram": {"enabled": False, "bot_token": "", "chat_id": ""},
        "priority": "medium",
        "only_on_changes": True,
    },
}

# é…ç½®å­—å…¸ï¼Œåˆå§‹åŒ–ä¸ºé»˜è®¤é…ç½®
config = json.loads(json.dumps(DEFAULT_CONFIG))
# é…ç½®è¯»å†™é”ï¼Œç¡®ä¿å¤šWorkerçº¿ç¨‹å®‰å…¨
import threading
config_lock = threading.RLock()
# å†…å­˜ç¼“å­˜ä¸Šæ¬¡è¿è¡Œæ—¶é—´
last_run_key = {"value": None}

# ---- CLIå·¥å…·å¤„ç† ----
if len(sys.argv) > 1 and sys.argv[1] == "--gen-hash":
    if len(sys.argv) > 2:
        password = sys.argv[2]
        # ç”Ÿæˆå¯†ç å“ˆå¸Œ
        raw_hash = generate_password_hash(password)
        safe_hash = base64.b64encode(raw_hash.encode("utf-8")).decode("utf-8")
        print(safe_hash)
        sys.exit(0)
    else:
        print("ç”¨æ³•: python prunemate.py --gen-hash <å¯†ç >")
        sys.exit(1)


def configure_logging():
    """é…ç½®æ—¥å¿—è®°å½•ï¼Œæ”¯æŒæ§åˆ¶å°å’Œæ–‡ä»¶æ»šåŠ¨æ—¥å¿—"""
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    ch = logging.StreamHandler()
    ch.setFormatter(logging.Formatter("%(message)s"))
    logger.addHandler(ch)
    try:
        Path("/var/log").mkdir(parents=True, exist_ok=True)
        fh = RotatingFileHandler("/var/log/prunemate.log", maxBytes=5_000_000, backupCount=3)
        fh.setFormatter(logging.Formatter("%(message)s"))
        logger.addHandler(fh)
    except Exception:
        logger.exception("æ–‡ä»¶æ—¥å¿—é…ç½®å¤±è´¥ï¼›ä»…ä½¿ç”¨æ§åˆ¶å°æ—¥å¿—ç»§ç»­è¿è¡Œã€‚")


configure_logging()


# æ—¶åŒºé…ç½®
tz_name = os.environ.get("PRUNEMATE_TZ", "UTC")
try:
    app_timezone = ZoneInfo(tz_name)
except Exception:
    logging.warning("æ—¶åŒº '%s' æ— æ•ˆï¼Œå›é€€åˆ°UTC", tz_name)
    app_timezone = ZoneInfo("UTC")

logging.info("ä½¿ç”¨æ—¶åŒº: %s", app_timezone)

# æ—¶é—´æ ¼å¼ï¼ˆ12å°æ—¶åˆ¶æˆ–24å°æ—¶åˆ¶ï¼‰
use_24h_format = os.environ.get("PRUNEMATE_TIME_24H", "true").lower() in ("true", "1", "yes")
logging.info("ä½¿ç”¨æ—¶é—´æ ¼å¼: %s", "24å°æ—¶åˆ¶" if use_24h_format else "12å°æ—¶åˆ¶")

# æŠ‘åˆ¶APSchedulerå†—é•¿çš„ä»»åŠ¡æ‰§è¡Œæ—¥å¿—
logging.getLogger("apscheduler.executors.default").setLevel(logging.WARNING)

# è°ƒåº¦å™¨åˆå§‹åŒ–
# åå°è°ƒåº¦å™¨ç”¨äºæ¯åˆ†é’Ÿå¿ƒè·³æ£€æŸ¥ï¼Œå®é™…ä»»åŠ¡åœ¨__main__ä¸­æ·»åŠ 
scheduler = BackgroundScheduler(
    timezone=app_timezone,
    job_defaults={
        "coalesce": False,
        "misfire_grace_time": 300,
    },
)
scheduler.start()


def log(message: str):
    """å¸¦æ—¶åŒºæ—¶é—´æˆ³çš„æ—¥å¿—è®°å½•"""
    now = datetime.datetime.now(app_timezone)
    timestamp = now.isoformat(timespec="seconds")
    logging.info("[%s] %s", timestamp, message)


def _redact_for_log(obj):
    """é€’å½’æ¸…ç†æ—¥å¿—ä¸­çš„æ•æ„Ÿä¿¡æ¯"""
    if isinstance(obj, dict):
        redacted = {}
        for k, v in obj.items():
            if k.lower() in {"token", "api_key", "apikey", "password", "secret"}:
                redacted[k] = "***"
            elif k.lower() == "url" and isinstance(v, str):
                # æ¸…ç†URLä¸­çš„ç”¨æˆ·åå’Œå¯†ç 
                parsed = urllib.parse.urlparse(v)
                if parsed.username or parsed.password:
                    clean_url = urllib.parse.urlunparse((
                        parsed.scheme,
                        f"***:***@{parsed.hostname}" + (f":{parsed.port}" if parsed.port else ""),
                        parsed.path,
                        parsed.params,
                        parsed.query,
                        parsed.fragment
                    ))
                    redacted[k] = clean_url
                else:
                    redacted[k] = v
            else:
                redacted[k] = _redact_for_log(v)
        return redacted
    if isinstance(obj, list):
        return [_redact_for_log(x) for x in obj]
    return obj


# ---- è·¨è¿›ç¨‹çš„ä¸Šæ¬¡è¿è¡Œæ—¶é—´ç®¡ç† ----
def _read_last_run_key() -> str | None:
    """ä»ç£ç›˜è¯»å–ä¸Šæ¬¡è¿è¡Œæ—¶é—´"""
    try:
        with FileLock(str(LAST_RUN_LOCK)):
            if LAST_RUN_FILE.exists():
                return LAST_RUN_FILE.read_text(encoding="utf-8").strip() or None
    except Exception:
        # è¯»å–å¤±è´¥æ—¶å›é€€åˆ°å†…å­˜ç¼“å­˜
        pass
    return None


def _write_last_run_key(key: str) -> None:
    """å°†ä¸Šæ¬¡è¿è¡Œæ—¶é—´å†™å…¥ç£ç›˜"""
    try:
        with FileLock(str(LAST_RUN_LOCK)):
            parent = LAST_RUN_FILE.parent
            parent.mkdir(parents=True, exist_ok=True)
            tmp = LAST_RUN_FILE.with_suffix(LAST_RUN_FILE.suffix + ".tmp")
            tmp.write_text(key, encoding="utf-8")
            try:
                tmp.chmod(0o600)
            except Exception:
                pass
            tmp.replace(LAST_RUN_FILE)
    except Exception:
        # å†™å…¥å¤±è´¥æ—¶å›é€€åˆ°å†…å­˜ç¼“å­˜
        pass


def _clear_last_run_key() -> None:
    """æ¸…é™¤å†…å­˜å’Œç£ç›˜ä¸Šçš„ä¸Šæ¬¡è¿è¡Œæ—¶é—´è®°å½•"""
    last_run_key["value"] = None
    try:
        with FileLock(str(LAST_RUN_LOCK)):
            if LAST_RUN_FILE.exists():
                LAST_RUN_FILE.unlink()
    except Exception:
        pass


# ---- å†å²ç»Ÿè®¡æ•°æ®ç®¡ç† ----
def load_stats() -> dict:
    """ä»ç£ç›˜åŠ è½½å†å²ç»Ÿè®¡æ•°æ®"""
    default_stats = {
        "total_space_reclaimed": 0,
        "containers_deleted": 0,
        "images_deleted": 0,
        "networks_deleted": 0,
        "volumes_deleted": 0,
        "build_cache_deleted": 0,
        "prune_runs": 0,
        "first_run": None,
        "last_run": None,
    }
    
    try:
        if STATS_FILE.exists():
            with open(STATS_FILE, "r", encoding="utf-8") as f:
                loaded_stats = json.load(f)
            
            merged_stats = json.loads(json.dumps(default_stats))
            for key in default_stats:
                if key in loaded_stats:
                    if key in {"total_space_reclaimed", "containers_deleted", "images_deleted", 
                              "networks_deleted", "volumes_deleted", "build_cache_deleted", "prune_runs"}:
                        try:
                            merged_stats[key] = int(loaded_stats[key])
                        except (ValueError, TypeError):
                            log(f"ç»Ÿè®¡å­—æ®µ '{key}' ç±»å‹æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼: 0")
                            merged_stats[key] = 0
                    else:
                        merged_stats[key] = loaded_stats[key]
            
            return merged_stats
    except json.JSONDecodeError as e:
        log(f"ç»Ÿè®¡æ–‡ä»¶æŸåï¼ˆæ— æ•ˆJSONï¼‰: {e}ã€‚ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œä¸‹æ¬¡ä¿å­˜å°†è¦†ç›–ã€‚")
    except Exception as e:
        log(f"ä» {STATS_FILE} åŠ è½½ç»Ÿè®¡æ•°æ®æ—¶å‡ºé”™: {e}")
    
    return json.loads(json.dumps(default_stats))


def save_stats(stats: dict) -> None:
    """åŸå­åŒ–ä¿å­˜ç»Ÿè®¡æ•°æ®åˆ°ç£ç›˜"""
    try:
        parent = STATS_FILE.parent
        parent.mkdir(parents=True, exist_ok=True)
        
        tmp_path = None
        try:
            with tempfile.NamedTemporaryFile("w", delete=False, dir=str(parent), encoding="utf-8") as tmp:
                json.dump(stats, tmp, indent=2)
                tmp.flush()
                os.fsync(tmp.fileno())
                tmp_path = Path(tmp.name)
            
            try:
                tmp_path.chmod(0o600)
            except Exception:
                pass
            
            tmp_path.replace(STATS_FILE)
            log(f"ç»Ÿè®¡æ•°æ®å·²ä¿å­˜åˆ° {STATS_FILE}")
        except Exception:
            if tmp_path and tmp_path.exists():
                try:
                    tmp_path.unlink()
                except Exception:
                    pass
            raise
    except Exception as e:
        log(f"ä¿å­˜ç»Ÿè®¡æ•°æ®æ—¶å‡ºé”™: {e}")


def update_stats(containers: int, images: int, networks: int, volumes: int, build_cache: int, space: int) -> None:
    """æ›´æ–°å†å²ç»Ÿè®¡æ•°æ®"""
    stats = load_stats()
    
    try:
        stats["containers_deleted"] = int(stats.get("containers_deleted") or 0) + int(containers or 0)
        stats["images_deleted"] = int(stats.get("images_deleted") or 0) + int(images or 0)
        stats["networks_deleted"] = int(stats.get("networks_deleted") or 0) + int(networks or 0)
        stats["volumes_deleted"] = int(stats.get("volumes_deleted") or 0) + int(volumes or 0)
        stats["build_cache_deleted"] = int(stats.get("build_cache_deleted") or 0) + int(build_cache or 0)
        stats["total_space_reclaimed"] = int(stats.get("total_space_reclaimed") or 0) + int(space or 0)
        stats["prune_runs"] = int(stats.get("prune_runs") or 0) + 1
    except (ValueError, TypeError) as e:
        log(f"ç»Ÿè®¡æ•°æ®æ›´æ–°æ—¶ç±»å‹é”™è¯¯: {e}ã€‚ç»Ÿè®¡æ•°æ®å¯èƒ½ä¸å®Œæ•´ã€‚")
    
    now = datetime.datetime.now(app_timezone).isoformat()
    if stats.get("first_run") is None:
        stats["first_run"] = now
    stats["last_run"] = now
    
    save_stats(stats)


def human_bytes(num: int) -> str:
    """å°†å­—èŠ‚æ•°è½¬æ¢ä¸ºäººç±»å¯è¯»çš„æ ¼å¼ï¼ˆB, KB, MB, GB, TB, PBï¼‰"""
    n = float(num)
    for unit in ["B", "KB", "MB", "GB", "TB"]:
        if n < 1024.0:
            return f"{n:.1f} {unit}"
        n /= 1024.0
    return f"{n:.1f} PB"


def format_time(time_str: str) -> str:
    """æ ¹æ®ç”¨æˆ·åå¥½æ ¼å¼åŒ–æ—¶é—´å­—ç¬¦ä¸²"""
    if use_24h_format:
        return time_str
    # å°†24å°æ—¶æ ¼å¼è½¬æ¢ä¸º12å°æ—¶æ ¼å¼
    try:
        parts = time_str.split(":")
        hour = int(parts[0])
        minute = parts[1] if len(parts) > 1 else "00"
        
        if hour == 0:
            return f"12:{minute} ä¸Šåˆ"
        elif hour < 12:
            return f"{hour}:{minute} ä¸Šåˆ"
        elif hour == 12:
            return f"12:{minute} ä¸‹åˆ"
        else:
            return f"{hour - 12}:{minute} ä¸‹åˆ"
    except Exception:
        return time_str


def describe_schedule() -> str:
    """ç”Ÿæˆå½“å‰è®¡åˆ’ä»»åŠ¡çš„äººç±»å¯è¯»æè¿°"""
    freq = config.get("frequency", "daily")
    time_str = config.get("time", "03:00")
    formatted_time = format_time(time_str)
    if freq == "daily":
        return f"æ¯æ—¥ {formatted_time} ({tz_name})"
    if freq == "weekly":
        day_key = config.get("day_of_week", "mon")
        day_names = {
            "mon": "å‘¨ä¸€", "tue": "å‘¨äºŒ", "wed": "å‘¨ä¸‰",
            "thu": "å‘¨å››", "fri": "å‘¨äº”", "sat": "å‘¨å…­", "sun": "å‘¨æ—¥",
        }
        return f"æ¯å‘¨ {day_names.get(day_key, day_key)} {formatted_time} ({tz_name})"
    if freq == "monthly":
        day_of_month = config.get("day_of_month", 1)
        return f"æ¯æœˆ {day_of_month} æ—¥ {formatted_time} ({tz_name})"
    return f"{freq} {formatted_time} ({tz_name})"


def validate_time(s: str) -> str:
    """éªŒè¯æ—¶é—´æ ¼å¼ï¼Œç¡®ä¿ä¸ºHH:MMæ ¼å¼"""
    try:
        parts = s.split(":", 1)
        h = int(parts[0])
        m = int(parts[1]) if len(parts) > 1 else 0
    except Exception as e:
        log(f"æ—¶é—´æ ¼å¼ '{s}' æ— æ•ˆ: {e}ã€‚å›é€€åˆ° 03:00")
        h, m = 3, 0
    h = max(0, min(23, h))
    m = max(0, min(59, m))
    return f"{h:02d}:{m:02d}"


def _deep_merge(base: dict, override: dict) -> None:
    """æ·±åº¦åˆå¹¶ä¸¤ä¸ªå­—å…¸"""
    for key, value in override.items():
        if key in base and isinstance(base[key], dict) and isinstance(value, dict):
            _deep_merge(base[key], value)
        else:
            base[key] = value


def effective_config():
    """è¿”å›å½“å‰æœ‰æ•ˆçš„é…ç½®"""
    freq = config.get("frequency", "daily")
    base = {
        "schedule_enabled": config.get("schedule_enabled", True),
        "frequency": freq,
        "time": config.get("time"),
        "prune_containers": config.get("prune_containers"),
        "prune_images": config.get("prune_images"),
        "prune_networks": config.get("prune_networks"),
        "prune_volumes": config.get("prune_volumes"),
        "prune_build_cache": config.get("prune_build_cache"),
        "docker_hosts": config.get("docker_hosts"),
        "notifications": config.get("notifications"),
    }
    if freq == "weekly":
        base["day_of_week"] = config.get("day_of_week")
    elif freq == "monthly":
        base["day_of_month"] = config.get("day_of_month")
    return base


def load_config(silent=False):
    """ä»ç£ç›˜åŠ è½½é…ç½®æ–‡ä»¶"""
    global config
    with config_lock:
        try:
            with open(CONFIG_PATH, "r", encoding="utf-8") as f:
                data = json.load(f)
            merged = json.loads(json.dumps(DEFAULT_CONFIG))
            _deep_merge(merged, data)

            # è¿ç§»æ—§ç‰ˆé€šçŸ¥é…ç½®
            if "notifications" not in data:
                has_gotify_keys = any(k in data for k in ("gotify_enabled", "gotify_url", "gotify_token"))
                has_ntfy_keys = any(k in data for k in ("ntfy_enabled", "ntfy_url", "ntfy_topic", "ntfy_token"))
                has_discord_keys = any(k in data for k in ("discord_enabled", "discord_webhook_url"))
                
                if has_gotify_keys or has_ntfy_keys or has_discord_keys:
                    if "notifications" not in merged:
                        merged["notifications"] = json.loads(json.dumps(DEFAULT_CONFIG["notifications"]))
                    
                    if has_gotify_keys:
                        got = {
                            "enabled": bool(data.get("gotify_enabled")),
                            "url": (data.get("gotify_url") or "").strip(),
                            "token": (data.get("gotify_token") or "").strip(),
                        }
                        merged["notifications"]["gotify"] = got
                    
                    if has_ntfy_keys:
                        ntf = {
                            "enabled": bool(data.get("ntfy_enabled")),
                            "url": (data.get("ntfy_url") or "").strip(),
                            "topic": (data.get("ntfy_topic") or "").strip(),
                            "token": (data.get("ntfy_token") or "").strip(),
                        }
                        merged["notifications"]["ntfy"] = ntf
                    
                    if has_discord_keys:
                        disc = {
                            "enabled": bool(data.get("discord_enabled")),
                            "webhook_url": (data.get("discord_webhook_url") or "").strip(),
                        }
                        merged["notifications"]["discord"] = disc
                    
                    if has_discord_keys and data.get("discord_enabled"):
                        merged["notifications"]["provider"] = "discord"
                    elif has_ntfy_keys and data.get("ntfy_enabled"):
                        merged["notifications"]["provider"] = "ntfy"
                    elif has_gotify_keys:
                        merged["notifications"]["provider"] = "gotify"
                    
                    if "gotify_only_on_changes" in data:
                        merged["notifications"]["only_on_changes"] = bool(data["gotify_only_on_changes"])
                    elif "ntfy_only_on_changes" in data:
                        merged["notifications"]["only_on_changes"] = bool(data["ntfy_only_on_changes"])
            
            if "notifications" not in merged:
                merged["notifications"] = json.loads(json.dumps(DEFAULT_CONFIG["notifications"]))
            
            # ç¡®ä¿æ‰€æœ‰é€šçŸ¥æä¾›å•†çš„é…ç½®éƒ½å­˜åœ¨
            for provider_key in ["gotify", "ntfy", "discord", "telegram"]:
                if provider_key not in merged["notifications"]:
                    merged["notifications"]["provider_key"] = json.loads(json.dumps(DEFAULT_CONFIG["notifications"][provider_key]))
            
            # è¿ç§»æ•°å­—ä¼˜å…ˆçº§åˆ°æ–‡æœ¬ä¼˜å…ˆçº§
            priority = merged.get("notifications", {}).get("priority")
            if isinstance(priority, int):
                if priority <= 3:
                    merged["notifications"]["priority"] = "low"
                elif priority <= 7:
                    merged["notifications"]["priority"] = "medium"
                else:
                    merged["notifications"]["priority"] = "high"
            elif not isinstance(priority, str) or priority not in ["low", "medium", "high"]:
                merged["notifications"]["priority"] = "medium"
            
            if "docker_hosts" not in merged or not isinstance(merged["docker_hosts"], list):
                merged["docker_hosts"] = json.loads(json.dumps(DEFAULT_CONFIG["docker_hosts"]))
            # æ¸…ç†æœ¬åœ°Dockerä¸»æœºè®°å½•
            merged["docker_hosts"] = [
                h for h in merged["docker_hosts"]
                if h.get("name") != "Local" and "unix://" not in h.get("url", "")
            ]
            # éªŒè¯æ¯ä¸ªä¸»æœºçš„å¿…å¡«å­—æ®µ
            for host in merged["docker_hosts"]:
                if "name" not in host:
                    host["name"] = "æœªå‘½å"
                if "url" not in host:
                    host["url"] = "tcp://localhost:2375"
                if "enabled" not in host:
                    host["enabled"] = True

            config = merged
            if not silent:
                log(f"ä» {CONFIG_PATH} åŠ è½½é…ç½®: {_redact_for_log(effective_config())}")
        except FileNotFoundError:
            if not silent:
                log(f"æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ {CONFIG_PATH}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®ã€‚")
            config = json.loads(json.dumps(DEFAULT_CONFIG))
        except Exception as e:
            if not silent:
                log(f"ä» {CONFIG_PATH} åŠ è½½é…ç½®æ—¶å‡ºé”™: {e}ã€‚ä½¿ç”¨é»˜è®¤é…ç½®ã€‚")
            config = json.loads(json.dumps(DEFAULT_CONFIG))


def save_config():
    """åŸå­åŒ–ä¿å­˜é…ç½®åˆ°ç£ç›˜"""
    with config_lock:
        try:
            path = Path(CONFIG_PATH)
            parent = path.parent or Path(".")
            parent.mkdir(parents=True, exist_ok=True)

            config_to_save = json.loads(json.dumps(config))
            if "docker_hosts" in config_to_save:
                config_to_save["docker_hosts"] = [
                    h for h in config_to_save["docker_hosts"]
                    if h.get("name") != "Local" and "unix://" not in h.get("url", "")
                ]

            tmp_path = None
            try:
                with tempfile.NamedTemporaryFile("w", delete=False, dir=str(parent), encoding="utf-8") as tmp:
                    json.dump(config_to_save, tmp, indent=2)
                    tmp.flush()
                    os.fsync(tmp.fileno())
                    tmp_path = Path(tmp.name)
                try:
                    tmp_path.chmod(0o600)
                except Exception:
                    pass
                tmp_path.replace(path)
                log(f"é…ç½®å·²ä¿å­˜åˆ° {path}: {_redact_for_log(config_to_save)}")
            finally:
                if tmp_path and tmp_path.exists() and tmp_path != path:
                    try:
                        tmp_path.unlink()
                    except Exception:
                        pass
        except Exception as e:
            log(f"ä¿å­˜é…ç½®åˆ° {CONFIG_PATH} æ—¶å¤±è´¥: {e}")


def _send_gotify(cfg: dict, title: str, message: str, priority: str = "medium") -> bool:
    """é€šè¿‡Gotifyå‘é€é€šçŸ¥"""
    if not cfg.get("enabled"):
        log("Gotifyå·²ç¦ç”¨ï¼›è·³è¿‡é€šçŸ¥ã€‚")
        return False
    url = (cfg.get("url") or "").strip()
    token = (cfg.get("token") or "").strip()
    if not url or not token:
        log("Gotifyå·²å¯ç”¨ä½†URLæˆ–ä»¤ç‰Œç¼ºå¤±ï¼›è·³è¿‡ã€‚")
        return False
    
    priority_map = {"low": 2, "medium": 5, "high": 8}
    gotify_priority = priority_map.get(priority, 2)
    
    endpoint = url.rstrip("/") + "/message?token=" + token
    payload = json.dumps({"title": title, "message": message, "priority": gotify_priority}).encode("utf-8")
    req = urllib.request.Request(endpoint, data=payload, headers={"Content-Type": "application/json"}, method="POST")
    try:
        with urllib.request.urlopen(req, timeout=5) as resp:
            log(f"Gotifyé€šçŸ¥å·²å‘é€ï¼ŒçŠ¶æ€={getattr(resp, 'status', '?')}")
            return True
    except Exception as e:
        log(f"å‘é€Gotifyé€šçŸ¥å¤±è´¥: {e}")
        return False


def _send_ntfy(cfg: dict, title: str, message: str, priority: str = "medium") -> bool:
    """é€šè¿‡ntfyå‘é€é€šçŸ¥"""
    if not cfg.get("enabled"):
        log("ntfyå·²ç¦ç”¨ï¼›è·³è¿‡é€šçŸ¥ã€‚")
        return False
    url = (cfg.get("url") or "").strip()
    topic = (cfg.get("topic") or "").strip()
    token = (cfg.get("token") or "").strip()
    
    if not url or not topic:
        log("ntfyå·²å¯ç”¨ä½†URLæˆ–ä¸»é¢˜ç¼ºå¤±ï¼›è·³è¿‡ã€‚")
        return False
    
    priority_map = {"low": 2, "medium": 3, "high": 5}
    ntfy_priority = priority_map.get(priority, 2)
    
    parsed = urllib.parse.urlparse(url)
    headers = {"Title": title, "Priority": str(ntfy_priority), "Content-Type": "text/plain"}
    
    if token:
        headers["Authorization"] = f"Bearer {token}"
        endpoint = url.rstrip("/") + "/" + topic.lstrip("/")
    elif parsed.username or parsed.password:
        clean_url = urllib.parse.urlunparse((
            parsed.scheme,
            parsed.hostname + (f":{parsed.port}" if parsed.port else ""),
            parsed.path,
            parsed.params,
            parsed.query,
            parsed.fragment
        ))
        username = parsed.username or ""
        password = parsed.password or ""
        credentials = f"{username}:{password}"
        encoded_credentials = base64.b64encode(credentials.encode("utf-8")).decode("ascii")
        headers["Authorization"] = f"Basic {encoded_credentials}"
        endpoint = clean_url.rstrip("/") + "/" + topic.lstrip("/")
    else:
        endpoint = url.rstrip("/") + "/" + topic.lstrip("/")
    
    payload = message.encode("utf-8")
    req = urllib.request.Request(endpoint, data=payload, headers=headers, method="POST")
    try:
        with urllib.request.urlopen(req, timeout=5) as resp:
            log(f"ntfyé€šçŸ¥å·²å‘é€ï¼ŒçŠ¶æ€={getattr(resp, 'status', '?')}")
            return True
    except Exception as e:
        log(f"å‘é€ntfyé€šçŸ¥å¤±è´¥: {e}")
        return False


def _send_discord(cfg: dict, title: str, message: str, priority: str = "medium") -> bool:
    """é€šè¿‡Discord Webhookå‘é€é€šçŸ¥"""
    if not cfg.get("enabled"):
        log("Discordå·²ç¦ç”¨ï¼›è·³è¿‡é€šçŸ¥ã€‚")
        return False
    webhook_url = (cfg.get("webhook_url") or "").strip()
    if not webhook_url:
        log("Discordå·²å¯ç”¨ä½†Webhook URLç¼ºå¤±ï¼›è·³è¿‡ã€‚")
        return False
    
    if not webhook_url.startswith("https://discord.com/api/webhooks/") and \
       not webhook_url.startswith("https://discordapp.com/api/webhooks/"):
        log(f"Discord Webhook URLæ ¼å¼æ— æ•ˆ: {webhook_url[:50]}...")
        return False
    
    color_map = {
        "low": 0x2ECC71,     # ç»¿è‰²ï¼ˆä¿¡æ¯ï¼‰
        "medium": 0xF39C12,  # æ©™è‰²ï¼ˆè­¦å‘Šï¼‰
        "high": 0xE74C3C,    # çº¢è‰²ï¼ˆä¸¥é‡ï¼‰
    }
    embed_color = color_map.get(priority, 0x2ECC71)
    
    payload = {
        "embeds": [{
            "title": title,
            "description": message,
            "color": embed_color,
            "timestamp": datetime.datetime.now(app_timezone).isoformat()
        }]
    }
    
    data = json.dumps(payload).encode("utf-8")
    headers = {
        "Content-Type": "application/json",
        "User-Agent": "PruneMate/1.3.0 (Dockeræ¸…ç†åŠ©æ‰‹)"
    }
    req = urllib.request.Request(webhook_url, data=data, headers=headers, method="POST")
    try:
        with urllib.request.urlopen(req, timeout=10) as resp:
            log(f"Discordé€šçŸ¥å·²å‘é€ï¼ŒçŠ¶æ€={getattr(resp, 'status', '?')}")
            return True
    except urllib.error.HTTPError as e:
        error_body = ""
        try:
            error_body = e.read().decode("utf-8")
        except Exception:
            pass
        log(f"Discord Webhook HTTPé”™è¯¯ {e.code}: {e.reason}ã€‚å“åº”ä½“: {error_body[:200]}")
        return False
    except urllib.error.URLError as e:
        log(f"Discord Webhookç½‘ç»œé”™è¯¯: {e.reason}")
        return False
    except Exception as e:
        log(f"å‘é€Discordé€šçŸ¥å¤±è´¥: {e}")
        return False


def _send_telegram(cfg: dict, title: str, message: str, priority: str = "medium") -> bool:
    """é€šè¿‡Telegram Bot APIå‘é€é€šçŸ¥"""
    if not cfg.get("enabled"):
        log("Telegramå·²ç¦ç”¨ï¼›è·³è¿‡é€šçŸ¥ã€‚")
        return False
    bot_token = (cfg.get("bot_token") or "").strip()
    chat_id = (cfg.get("chat_id") or "").strip()
    if not bot_token or not chat_id:
        log("Telegramå·²å¯ç”¨ä½†bot_tokenæˆ–chat_idç¼ºå¤±ï¼›è·³è¿‡ã€‚")
        return False
    
    disable_notification = (priority == "low")
    
    full_message = f"<b>{title}</b>\n\n{message}"
    
    api_url = f"https://api.telegram.org/bot{bot_token}/sendMessage"
    
    payload = json.dumps({
        "chat_id": chat_id,
        "text": full_message,
        "parse_mode": "HTML",
        "disable_notification": disable_notification
    }).encode("utf-8")
    
    req = urllib.request.Request(
        api_url,
        data=payload,
        headers={
            "Content-Type": "application/json",
            "User-Agent": "PruneMate/1.3.0 (Dockeræ¸…ç†åŠ©æ‰‹)"
        },
        method="POST"
    )
    
    try:
        with urllib.request.urlopen(req, timeout=10) as resp:
            result = json.loads(resp.read().decode("utf-8"))
            if result.get("ok"):
                log(f"Telegramé€šçŸ¥å·²å‘é€ï¼Œæ¶ˆæ¯ID={result.get('result', {}).get('message_id', '?')}")
                return True
            else:
                log(f"Telegram APIè¿”å›ok=false: {result}")
                return False
    except Exception as e:
        log(f"å‘é€Telegramé€šçŸ¥å¤±è´¥: {e}")
        return False


def send_notification(title: str, message: str, priority: str = "medium") -> bool:
    """ä½¿ç”¨é…ç½®çš„é€šçŸ¥æä¾›å•†å‘é€é€šçŸ¥"""
    notcfg = config.get("notifications", DEFAULT_CONFIG["notifications"])
    provider = (notcfg.get("provider") or "gotify").lower()
    if provider == "gotify":
        return _send_gotify(notcfg.get("gotify", {}), title, message, priority)
    if provider == "ntfy":
        return _send_ntfy(notcfg.get("ntfy", {}), title, message, priority)
    if provider == "discord":
        return _send_discord(notcfg.get("discord", {}), title, message, priority)
    if provider == "telegram":
        return _send_telegram(notcfg.get("telegram", {}), title, message, priority)
    log(f"æœªçŸ¥çš„é€šçŸ¥æä¾›å•† '{provider}'; è·³è¿‡é€šçŸ¥ã€‚")
    return False


def create_docker_client(host_url: str):
    """åˆ›å»ºDockerå®¢æˆ·ç«¯å®ä¾‹"""
    if docker is None:
        log("Docker SDKä¸å¯ç”¨ã€‚")
        return None
    
    try:
        if host_url.startswith("unix://"):
            return docker.DockerClient(base_url=host_url)
        elif host_url.startswith("tcp://") or host_url.startswith("http://") or host_url.startswith("https://"):
            return docker.DockerClient(base_url=host_url)
        else:
            return docker.DockerClient(base_url=host_url)
    except Exception as e:
        log(f"ä¸º {host_url} åˆ›å»ºDockerå®¢æˆ·ç«¯å¤±è´¥: {e}")
        return None


def get_prune_preview() -> dict:
    """è·å–æ¸…ç†é¢„è§ˆï¼Œä¸å®é™…æ‰§è¡Œæ¸…ç†"""
    load_config(silent=True)
    
    if not any([
        config.get("prune_containers"),
        config.get("prune_images"),
        config.get("prune_networks"),
        config.get("prune_volumes"),
        config.get("prune_build_cache"),
    ]):
        return {"error": "æœªé€‰æ‹©ä»»ä½•æ¸…ç†é€‰é¡¹", "hosts": []}
    
    if docker is None:
        return {"error": "Docker SDKä¸å¯ç”¨", "hosts": []}
    
    docker_hosts = config.get("docker_hosts", [])
    enabled_external_hosts = [
        h for h in docker_hosts 
        if h.get("enabled", True) and h.get("name") != "Local" and "unix://" not in h.get("url", "")
    ]
    
    all_hosts = [
        {"name": "æœ¬åœ°", "url": "unix:///var/run/docker.sock", "enabled": True}
    ] + enabled_external_hosts
    
    preview_results = []
    total_containers = 0
    total_images = 0
    total_networks = 0
    total_volumes = 0
    total_build_cache = 0
    
    for host in all_hosts:
        host_name = host.get("name", "æœªå‘½å")
        host_url = host.get("url", "unix:///var/run/docker.sock")
        
        client = None
        try:
            client = create_docker_client(host_url)
            if client is None:
                preview_results.append({
                    "name": host_name,
                    "url": host_url,
                    "success": False,
                    "error": "è¿æ¥å¤±è´¥",
                    "containers": [],
                    "images": [],
                    "networks": [],
                    "volumes": [],
                    "build_cache": []
                })
                continue
            
            containers_list = []
            images_list = []
            networks_list = []
            volumes_list = []
            build_cache_list = []
            
            if config.get("prune_containers"):
                try:
                    all_containers = client.containers.list(all=True)
                    stopped_containers = [c for c in all_containers if c.status in ["exited", "dead", "created"]]
                    containers_list = [
                        {"id": c.short_id, "name": c.name, "status": c.status}
                        for c in stopped_containers
                    ]
                except Exception as e:
                    log(f"[{host_name}] åˆ—å‡ºå®¹å™¨æ—¶å‡ºé”™: {e}")
            
            if config.get("prune_images"):
                try:
                    all_images = client.images.list()
                    used_image_ids = set()
                    for container in client.containers.list(all=True):
                        img_id = container.attrs.get("Image")
                        if img_id:
                            used_image_ids.add(img_id)
                    
                    unused_images = [img for img in all_images if img.id not in used_image_ids]
                    images_list = [
                        {
                            "id": img.short_id,
                            "tags": img.tags[:3] if img.tags else ["<none>"],
                            "size": human_bytes(img.attrs.get("Size", 0))
                        }
                        for img in unused_images
                    ]
                except Exception as e:
                    log(f"[{host_name}] åˆ—å‡ºé•œåƒæ—¶å‡ºé”™: {e}")
            
            if config.get("prune_networks"):
                try:
                    networks = client.networks.list()
                    unused_networks = []
                    
                    running_network_ids = set()
                    for container in client.containers.list(filters={"status": "running"}):
                        network_settings = container.attrs.get("NetworkSettings", {}).get("Networks", {})
                        for net_name, net_info in network_settings.items():
                            if net_info.get("NetworkID"):
                                running_network_ids.add(net_info["NetworkID"])
                    
                    for net in networks:
                        if net.name in ["bridge", "host", "none"]:
                            continue
                        if net.id in running_network_ids:
                            continue
                        unused_networks.append(net)
                    
                    networks_list = [
                        {"id": net.short_id, "name": net.name}
                        for net in unused_networks
                    ]
                except Exception as e:
                    log(f"[{host_name}] åˆ—å‡ºç½‘ç»œæ—¶å‡ºé”™: {e}")
            
            if config.get("prune_volumes"):
                try:
                    all_volumes_result = client.volumes.list()
                    all_volumes = all_volumes_result if all_volumes_result else []
                    used_volume_names = set()
                    for container in client.containers.list(all=True):
                        for mount in container.attrs.get("Mounts", []):
                            if mount.get("Type") == "volume":
                                used_volume_names.add(mount.get("Name"))
                    
                    unused_volumes = [v for v in all_volumes if v.name not in used_volume_names]
                    volumes_list = [
                        {"name": v.name, "driver": v.attrs.get("Driver", "local")}
                        for v in unused_volumes
                    ]
                except Exception as e:
                    log(f"[{host_name}] åˆ—å‡ºå·æ—¶å‡ºé”™: {e}")
            
            if config.get("prune_build_cache"):
                try:
                    df_result = client.api.df()
                    build_cache_info = df_result.get("BuildCache", [])
                    
                    reclaimable_cache = []
                    for c in build_cache_info:
                        if "Reclaimable" in c:
                            if c["Reclaimable"]:
                                reclaimable_cache.append(c)
                        elif not c.get("InUse", False):
                            reclaimable_cache.append(c)
                    
                    build_cache_list = [
                        {
                            "id": c.get("ID", "")[:12],
                            "type": c.get("Type", "unknown"),
                            "size": human_bytes(c.get("Size", 0)),
                            "reclaimable": c.get("Reclaimable", True),
                            "inUse": c.get("InUse", False)
                        }
                        for c in reclaimable_cache
                    ]
                    
                    if build_cache_list:
                        log(f"[{host_name}] é¢„è§ˆå‘ç° {len(build_cache_list)} ä¸ªå¯å›æ”¶çš„æ„å»ºç¼“å­˜æ¡ç›®")
                except Exception as e:
                    log(f"[{host_name}] åˆ—å‡ºæ„å»ºç¼“å­˜æ—¶å‡ºé”™: {e}")
            
            total_containers += len(containers_list)
            total_images += len(images_list)
            total_networks += len(networks_list)
            total_volumes += len(volumes_list)
            total_build_cache += len(build_cache_list)
            
            preview_results.append({
                "name": host_name,
                "url": host_url,
                "success": True,
                "containers": containers_list,
                "images": images_list,
                "networks": networks_list,
                "volumes": volumes_list,
                "build_cache": build_cache_list,
                "totals": {
                    "containers": len(containers_list),
                    "images": len(images_list),
                    "networks": len(networks_list),
                    "volumes": len(volumes_list),
                    "build_cache": len(build_cache_list)
                }
            })
            
        except Exception as e:
            log(f"[{host_name}] è·å–é¢„è§ˆæ—¶å‡ºé”™: {e}")
            preview_results.append({
                "name": host_name,
                "url": host_url,
                "success": False,
                "error": str(e),
                "containers": [],
                "images": [],
                "networks": [],
                "volumes": [],
                "build_cache": []
            })
        finally:
            if client is not None:
                try:
                    client.close()
                except Exception:
                    pass
    
    return {
        "hosts": preview_results,
        "totals": {
            "containers": total_containers,
            "images": total_images,
            "networks": total_networks,
            "volumes": total_volumes,
            "build_cache": total_build_cache
        }
    }


def run_prune_job(origin: str = "unknown", wait: bool = False) -> bool:
    """æ‰§è¡ŒDockeræ¸…ç†ä»»åŠ¡"""
    load_config(silent=True)
    
    lock = FileLock(str(LOCK_FILE))
    acquired = False
    try:
        if wait:
            try:
                lock.acquire(timeout=0)
                acquired = True
                log(f"{origin.capitalize()} è§¦å‘: å·²è·å–æ¸…ç†é”ã€‚")
            except Timeout:
                log(f"{origin.capitalize()} è§¦å‘: ç­‰å¾…æ­£åœ¨è¿è¡Œçš„æ¸…ç†ä»»åŠ¡å®Œæˆâ€¦")
                try:
                    lock.acquire(timeout=300)
                    acquired = True
                except Timeout:
                    log(f"{origin.capitalize()} è§¦å‘: å·²ç­‰å¾…300ç§’; è·³è¿‡æœ¬æ¬¡è¿è¡Œã€‚")
                    return False
        else:
            try:
                lock.acquire(timeout=0)
                acquired = True
            except Timeout:
                log(f"{origin.capitalize()} è§¦å‘: æ¸…ç†ä»»åŠ¡å·²åœ¨è¿›è¡Œä¸­; è·³è¿‡æœ¬æ¬¡è¿è¡Œã€‚")
                return False

        log("å¼€å§‹æ¸…ç†ä»»åŠ¡ï¼Œé…ç½®å¦‚ä¸‹:")
        log(str(_redact_for_log(effective_config())))

        if not any([
            config.get("prune_containers"),
            config.get("prune_images"),
            config.get("prune_networks"),
            config.get("prune_volumes"),
            config.get("prune_build_cache"),
        ]):
            log("æœªé€‰æ‹©ä»»ä½•æ¸…ç†é€‰é¡¹ã€‚ä»»åŠ¡è·³è¿‡ã€‚")
            return False

        if docker is None:
            log("Docker SDKä¸å¯ç”¨; ç»ˆæ­¢æ¸…ç†ä»»åŠ¡ã€‚")
            return False

        docker_hosts = config.get("docker_hosts", [])
        enabled_external_hosts = [
            h for h in docker_hosts 
            if h.get("enabled", True) and h.get("name") != "Local" and "unix://" not in h.get("url", "")
        ]
        
        all_hosts = [
            {"name": "æœ¬åœ°", "url": "unix:///var/run/docker.sock", "enabled": True}
        ] + enabled_external_hosts
        
        log(f"å¤„ç† {len(all_hosts)} ä¸ªä¸»æœº (1ä¸ªæœ¬åœ° + {len(enabled_external_hosts)} ä¸ªå¤–éƒ¨)...")
        
        total_containers_deleted = 0
        total_images_deleted = 0
        total_networks_deleted = 0
        total_volumes_deleted = 0
        total_build_cache_deleted = 0
        total_space_reclaimed = 0
        
        host_results = []
        
        for host in all_hosts:
            host_name = host.get("name", "æœªå‘½å")
            host_url = host.get("url", "unix:///var/run/docker.sock")
            
            log(f"--- å¤„ç†ä¸»æœº: {host_name} ({host_url}) ---")
            
            client = None
            try:
                client = create_docker_client(host_url)
                if client is None:
                    log(f"æ— æ³•è¿æ¥åˆ° {host_name}; è·³è¿‡æ­¤ä¸»æœºã€‚")
                    host_results.append({
                        "name": host_name,
                        "url": host_url,
                        "success": False,
                        "error": "è¿æ¥å¤±è´¥",
                        "containers": 0,
                        "images": 0,
                        "networks": 0,
                        "volumes": 0,
                        "build_cache": 0,
                        "space": 0,
                    })
                    continue
                
                containers_deleted = images_deleted = networks_deleted = volumes_deleted = build_cache_deleted = 0
                space_reclaimed = 0

                if config.get("prune_containers"):
                    try:
                        log(f"[{host_name}] æ¸…ç†å®¹å™¨â€¦")
                        r = client.containers.prune()
                        log(f"[{host_name}] å®¹å™¨æ¸…ç†ç»“æœ: {r}")
                        containers_deleted = len(r.get("ContainersDeleted") or [])
                        space_reclaimed += int(r.get("SpaceReclaimed") or 0)
                    except Exception as e:
                        log(f"[{host_name}] æ¸…ç†å®¹å™¨æ—¶å‡ºé”™: {e}")

                if config.get("prune_images"):
                    try:
                        log(f"[{host_name}] æ¸…ç†æ‰€æœ‰æœªä½¿ç”¨çš„é•œåƒâ€¦")
                        r = client.images.prune(filters={"dangling": False})
                        log(f"[{host_name}] é•œåƒæ¸…ç†ç»“æœ: {r}")
                        deleted_list = r.get("ImagesDeleted") or []
                        images_deleted = len(deleted_list)
                        space_reclaimed += int(r.get("SpaceReclaimed") or 0)
                    except Exception as e:
                        log(f"[{host_name}] æ¸…ç†é•œåƒæ—¶å‡ºé”™: {e}")

                if config.get("prune_networks"):
                    try:
                        log(f"[{host_name}] æ¸…ç†ç½‘ç»œâ€¦")
                        r = client.networks.prune()
                        log(f"[{host_name}] ç½‘ç»œæ¸…ç†ç»“æœ: {r}")
                        networks_deleted = len(r.get("NetworksDeleted") or [])
                    except Exception as e:
                        log(f"[{host_name}] æ¸…ç†ç½‘ç»œæ—¶å‡ºé”™: {e}")

                if config.get("prune_volumes"):
                    try:
                        log(f"[{host_name}] æ¸…ç†æ‰€æœ‰æœªä½¿ç”¨çš„å·ï¼ˆåŒ…æ‹¬å‘½åå·ï¼‰â€¦")
                        r = client.volumes.prune(filters={"all": True})
                        log(f"[{host_name}] å·æ¸…ç†ç»“æœ: {r}")
                        volumes_deleted_list = r.get("VolumesDeleted") or []
                        volumes_deleted = len(volumes_deleted_list) if volumes_deleted_list else 0
                        space_reclaimed += int(r.get("SpaceReclaimed") or 0)
                    except Exception as e:
                        log(f"[{host_name}] æ¸…ç†å·æ—¶å‡ºé”™: {e}")

                if config.get("prune_build_cache"):
                    try:
                        log(f"[{host_name}] æ¸…ç†æ„å»ºç¼“å­˜â€¦")
                        r = client.api.prune_builds()
                        log(f"[{host_name}] æ„å»ºç¼“å­˜æ¸…ç†ç»“æœ: {r}")
                        cache_ids_deleted = r.get("CachesDeleted") or []
                        build_cache_deleted = len(cache_ids_deleted) if cache_ids_deleted else 0
                        space_reclaimed += int(r.get("SpaceReclaimed") or 0)
                    except Exception as e:
                        log(f"[{host_name}] æ¸…ç†æ„å»ºç¼“å­˜æ—¶å‡ºé”™: {e}")

                log(f"[{host_name}] æ¸…ç†å®Œæˆ: å®¹å™¨={containers_deleted}, é•œåƒ={images_deleted}, ç½‘ç»œ={networks_deleted}, å·={volumes_deleted}, æ„å»ºç¼“å­˜={build_cache_deleted}, ç©ºé—´={human_bytes(space_reclaimed)}")
                
                total_containers_deleted += containers_deleted
                total_images_deleted += images_deleted
                total_networks_deleted += networks_deleted
                total_volumes_deleted += volumes_deleted
                total_build_cache_deleted += build_cache_deleted
                total_space_reclaimed += space_reclaimed
                
                host_results.append({
                    "name": host_name,
                    "url": host_url,
                    "success": True,
                    "containers": containers_deleted,
                    "images": images_deleted,
                    "networks": networks_deleted,
                    "volumes": volumes_deleted,
                    "build_cache": build_cache_deleted,
                    "space": space_reclaimed,
                })
                
            except Exception as e:
                log(f"[{host_name}] æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°æ„å¤–é”™è¯¯: {e}")
                host_results.append({
                    "name": host_name,
                    "url": host_url,
                    "success": False,
                    "error": str(e),
                    "containers": 0,
                    "images": 0,
                    "networks": 0,
                    "volumes": 0,
                    "build_cache": 0,
                    "space": 0,
                })
            finally:
                if client is not None:
                    try:
                        client.close()
                    except Exception:
                        pass

        log("æ‰€æœ‰ä¸»æœºçš„æ¸…ç†ä»»åŠ¡å·²å®Œæˆã€‚")

        anything_deleted = any([
            total_containers_deleted, total_images_deleted, total_networks_deleted,
            total_volumes_deleted, total_build_cache_deleted, total_space_reclaimed > 0
        ])

        update_stats(
            containers=total_containers_deleted,
            images=total_images_deleted,
            networks=total_networks_deleted,
            volumes=total_volumes_deleted,
            build_cache=total_build_cache_deleted,
            space=total_space_reclaimed
        )

        if not anything_deleted and config.get("notifications", {}).get("only_on_changes", True):
            log("æœªæ¸…ç†ä»»ä½•èµ„æº; è·³è¿‡é€šçŸ¥ã€‚")
            return True

        summary_lines = [
            f"ğŸ“… {describe_schedule()}",
            "",
        ]
        
        if len(all_hosts) > 1:
            summary_lines.append("ğŸ“Š æŒ‰ä¸»æœºç»Ÿè®¡ç»“æœ:")
        
        for result in host_results:
            if result.get("success"):
                has_deletions = any([result.get('containers'), result.get('images'), result.get('networks'), result.get('volumes'), result.get('build_cache')])
                
                if has_deletions:
                    summary_lines.append(f"â€¢ {result['name']}")
                    if result.get('containers'):
                        summary_lines.append(f"  - ğŸ—‘ï¸ {result['containers']} ä¸ªå®¹å™¨")
                    if result.get('images'):
                        summary_lines.append(f"  - ğŸ’¿ {result['images']} ä¸ªé•œåƒ")
                    if result.get('networks'):
                        summary_lines.append(f"  - ğŸŒ {result['networks']} ä¸ªç½‘ç»œ")
                    if result.get('volumes'):
                        summary_lines.append(f"  - ğŸ“¦ {result['volumes']} ä¸ªå·")
                    if result.get('build_cache'):
                        summary_lines.append(f"  - ğŸ—ï¸ {result['build_cache']} ä¸ªæ„å»ºç¼“å­˜")
                    if result['space']:
                        summary_lines.append(f"  - ğŸ’¾ å›æ”¶ç©ºé—´ {human_bytes(result['space'])}")
                else:
                    summary_lines.append(f"â€¢ {result['name']}: âœ… æ— èµ„æºéœ€è¦æ¸…ç†")
            else:
                summary_lines.append(f"â€¢ {result['name']}: âŒ {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        if len(all_hosts) > 1:
            summary_lines.append("")
        
        if len(all_hosts) > 1:
            summary_lines.append("ğŸ“ˆ æ‰€æœ‰ä¸»æœºæ€»è®¡:")
        if anything_deleted:
            if total_containers_deleted:
                summary_lines.append(f"  - ğŸ—‘ï¸ å®¹å™¨: {total_containers_deleted}")
            if total_images_deleted:
                summary_lines.append(f"  - ğŸ’¿ é•œåƒ: {total_images_deleted}")
            if total_networks_deleted:
                summary_lines.append(f"  - ğŸŒ ç½‘ç»œ: {total_networks_deleted}")
            if total_volumes_deleted:
                summary_lines.append(f"  - ğŸ“¦ å·: {total_volumes_deleted}")
            if total_build_cache_deleted:
                summary_lines.append(f"  - ğŸ—ï¸ æ„å»ºç¼“å­˜: {total_build_cache_deleted}")
            if total_space_reclaimed:
                summary_lines.append(f"  - ğŸ’¾ å›æ”¶ç©ºé—´: {human_bytes(total_space_reclaimed)}")
        else:
            summary_lines.append("âœ… æœ¬æ¬¡è¿è¡Œæ— èµ„æºéœ€è¦æ¸…ç†")

        message = "\n".join(summary_lines)
        notif_priority = config.get("notifications", {}).get("priority", "medium")
        send_notification("PruneMate æ¸…ç†å®Œæˆ", message, priority=notif_priority)
        
        return True
    
    finally:
        if acquired:
            try:
                lock.release()
            except Exception:
                pass


def compute_run_key(now: datetime.datetime) -> str:
    """ä¸ºå½“å‰è®¡åˆ’ä»»åŠ¡ç”Ÿæˆå”¯ä¸€é”®"""
    freq = config.get("frequency", "daily")
    time_str = config.get("time", "03:00")
    date_str = now.date().isoformat()
    if freq == "daily":
        return f"daily-{date_str}-{time_str}"
    elif freq == "weekly":
        year, week, _ = now.isocalendar()
        return f"weekly-{year}-W{week}-{time_str}"
    elif freq == "monthly":
        return f"monthly-{now.year}-{now.month}-{time_str}"
    else:
        return f"daily-{date_str}-{time_str}"


def check_and_run_scheduled_job():
    """æ£€æŸ¥æ˜¯å¦åˆ°è¾¾è®¡åˆ’æ¸…ç†æ—¶é—´å¹¶æ‰§è¡Œæ¸…ç†"""
    load_config(silent=True)
    
    if not config.get("schedule_enabled", True):
        return
    
    now = datetime.datetime.now(app_timezone)
    freq = config.get("frequency", "daily")
    try:
        time_str = config.get("time", "03:00")
        hour_cfg, minute_cfg = [int(x) for x in time_str.split(":", 1)]
    except Exception:
        hour_cfg, minute_cfg = 3, 0

    hour_now = now.hour
    minute_now = now.minute
    should_run = False

    if freq == "daily":
        if hour_now == hour_cfg and minute_now == minute_cfg:
            should_run = True
    elif freq == "weekly":
        day_map = {"mon": 0, "tue": 1, "wed": 2, "thu": 3, "fri": 4, "sat": 5, "sun": 6}
        cfg_dow = day_map.get(config.get("day_of_week", "mon"), 0)
        if now.weekday() == cfg_dow and hour_now == hour_cfg and minute_now == minute_cfg:
            should_run = True
    elif freq == "monthly":
        try:
            dom_cfg = int(config.get("day_of_month", 1))
        except Exception:
            dom_cfg = 1
        dom_cfg = max(1, min(31, dom_cfg))
        _, last_day = calendar.monthrange(now.year, now.month)
        actual_dom = min(dom_cfg, last_day)
        if now.day == actual_dom and hour_now == hour_cfg and minute_now == minute_cfg:
            should_run = True

    if not should_run:
        return

    key = compute_run_key(now)
    if last_run_key["value"] == key:
        log(f"è®¡åˆ’ä»»åŠ¡å·²è·³è¿‡: å·²ä¸ºé”® '{key}' æ‰§è¡Œè¿‡ï¼ˆå†…å­˜æ£€æŸ¥ï¼‰")
        return
    disk_key = _read_last_run_key()
    if disk_key == key:
        last_run_key["value"] = key
        log(f"è®¡åˆ’ä»»åŠ¡å·²è·³è¿‡: å·²ä¸ºé”® '{key}' æ‰§è¡Œè¿‡ï¼ˆç£ç›˜æ£€æŸ¥ï¼‰")
        return

    log(f"åˆ°è¾¾è®¡åˆ’æ—¶é—´ ({freq}) åœ¨ {hour_now:02d}:{minute_now:02d}ï¼Œæ‰§è¡Œæ¸…ç†ã€‚")
    last_run_key["value"] = key
    _write_last_run_key(key)
    ran = run_prune_job(origin="scheduled", wait=False)
    if not ran:
        pass


def heartbeat():
    """å¿ƒè·³å‡½æ•°ï¼Œæ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡è®¡åˆ’ä»»åŠ¡"""
    log("å¿ƒè·³: è°ƒåº¦å™¨è¿è¡Œæ­£å¸¸ã€‚")
    check_and_run_scheduled_job()


# ---- è®¤è¯é€»è¾‘ ----
def is_auth_enabled():
    """æ£€æŸ¥æ˜¯å¦å¯ç”¨äº†èº«ä»½éªŒè¯"""
    return bool(os.environ.get("PRUNEMATE_AUTH_PASSWORD_HASH"))


def check_auth(username, password):
    """éªŒè¯ç”¨æˆ·åå’Œå¯†ç """
    expected_user = os.environ.get("PRUNEMATE_AUTH_USER", "admin")
    password_hash = os.environ.get("PRUNEMATE_AUTH_PASSWORD_HASH")

    if not password_hash:
        return False

    if username != expected_user:
        return False

    try:
        password_hash = base64.b64decode(password_hash).decode("utf-8")
    except Exception:
        pass
    
    try:
        return check_password_hash(password_hash, password)
    except Exception:
        return False


def request_wants_json():
    """æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦éœ€è¦JSONå“åº”"""
    best = request.accept_mimetypes.best_match(['application/json', 'text/html'])
    return best == 'application/json' and request.accept_mimetypes[best] > request.accept_mimetypes['text/html']


@app.before_request
def require_auth():
    """è¯·æ±‚å‰æ£€æŸ¥èº«ä»½éªŒè¯"""
    if not is_auth_enabled():
        return

    if request.endpoint in ('static', 'login', 'logout', 'stats', 'api_stats'):
        return

    if session.get('logged_in'):
        return

    auth = request.authorization
    if auth:
        if check_auth(auth.username, auth.password):
            return
    
    ua = request.user_agent.string.lower()
    is_browser = any(x in ua for x in ['mozilla', 'chrome', 'safari', 'edge']) and 'curl' not in ua and 'python' not in ua
    
    if not is_browser or request_wants_json() or request.path.startswith('/api/'):
        return Response(
            'æ— æ³•éªŒè¯æ‚¨çš„è®¿é—®æƒé™ã€‚\n'
            'æ‚¨éœ€è¦ä½¿ç”¨æ­£ç¡®çš„å‡­æ®ç™»å½•ã€‚', 401,
            {'WWW-Authenticate': 'Basic realm="PruneMate ç™»å½•"'}
        )
    
    return redirect(url_for('login'))


@app.route("/login", methods=["GET", "POST"])
def login():
    """ç™»å½•é¡µé¢å¤„ç†"""
    if session.get('logged_in'):
        return redirect(url_for('index'))

    if not is_auth_enabled():
        return redirect(url_for("index"))
        
    if request.method == "POST":
        username = request.form.get("username")
        password = request.form.get("password")
        
        if check_auth(username, password):
            session['logged_in'] = True
            session['user'] = username
            
            next_url = request.args.get('next')
            if not next_url or next_url.startswith('//') or ':' in next_url:
                next_url = url_for('index')
            
            return redirect(next_url)
        else:
            flash("æ— æ•ˆçš„å‡­æ®", "error")
            
    return render_template("login.html")


@app.route("/logout")
def logout():
    """ç™»å‡ºå¤„ç†"""
    session.clear()
    return redirect(url_for("login"))


@app.route("/")
def index():
    """ä¸»é¡µé…ç½®é¡µé¢"""
    load_config(silent=True)
    return render_template("index.html", config=config, timezone=tz_name, config_path=CONFIG_PATH, use_24h=use_24h_format)


@app.route("/update", methods=["POST"])
def update():
    """å¤„ç†é…ç½®æ›´æ–°"""
    load_config(silent=True)
    old_config = json.loads(json.dumps(config))

    frequency = request.form.get("frequency", "daily")
    
    if use_24h_format:
        time_value = request.form.get("time", "03:00")
    else:
        try:
            hour_12 = int(request.form.get("time_hour", "3"))
            minute = int(request.form.get("time_minute", "0"))
            period = request.form.get("time_period", "AM")
            
            hour_12 = max(1, min(12, hour_12))
            minute = max(0, min(59, minute))
            
            if period == "AM":
                hour_24 = 0 if hour_12 == 12 else hour_12
            else:
                hour_24 = 12 if hour_12 == 12 else hour_12 + 12
            
            time_value = f"{hour_24:02d}:{minute:02d}"
        except Exception:
            time_value = "03:00"
    
    day_of_week = request.form.get("day_of_week", "mon")
    raw_dom = request.form.get("day_of_month", "1")
    try:
        day_of_month = int(raw_dom)
    except Exception:
        day_of_month = 1
    day_of_month = max(1, min(31, day_of_month))

    schedule_enabled = "schedule_enabled" in request.form
    prune_containers = "prune_containers" in request.form
    prune_images = "prune_images" in request.form
    prune_networks = "prune_networks" in request.form
    prune_volumes = "prune_volumes" in request.form
    prune_build_cache = "prune_build_cache" in request.form

    provider = request.form.get("notifications_provider", "gotify")
    gotify_enabled = "gotify_enabled" in request.form
    gotify_url = (request.form.get("gotify_url") or "").strip()
    gotify_token = (request.form.get("gotify_token") or "").strip()
    ntfy_enabled = "ntfy_enabled" in request.form
    ntfy_url = (request.form.get("ntfy_url") or "").strip()
    ntfy_topic = (request.form.get("ntfy_topic") or "").strip()
    ntfy_token = (request.form.get("ntfy_token") or "").strip()
    discord_enabled = "discord_enabled" in request.form
    discord_webhook_url = (request.form.get("discord_webhook_url") or "").strip()
    telegram_enabled = "telegram_enabled" in request.form
    telegram_bot_token = (request.form.get("telegram_bot_token") or "").strip()
    telegram_chat_id = (request.form.get("telegram_chat_id") or "").strip()
    notification_priority = request.form.get("notification_priority", "medium").strip().lower()
    if notification_priority not in ["low", "medium", "high"]:
        notification_priority = "medium"
    only_on_changes = "notifications_only_on_changes" in request.form

    if provider == "gotify" and not gotify_enabled and gotify_url and gotify_token:
        gotify_enabled = True
    if provider == "ntfy" and not ntfy_enabled and ntfy_url and ntfy_topic:
        ntfy_enabled = True
    if provider == "discord" and not discord_enabled and discord_webhook_url:
        discord_enabled = True
    if provider == "telegram" and not telegram_enabled and telegram_bot_token and telegram_chat_id:
        telegram_enabled = True

    time_value = validate_time(time_value)

    new_values = {
        "schedule_enabled": schedule_enabled,
        "frequency": frequency,
        "time": time_value,
        "day_of_week": day_of_week,
        "day_of_month": day_of_month,
        "prune_containers": prune_containers,
        "prune_images": prune_images,
        "prune_networks": prune_networks,
        "prune_volumes": prune_volumes,
        "prune_build_cache": prune_build_cache,
        "notifications": {
            "provider": provider,
            "gotify": {"enabled": gotify_enabled, "url": gotify_url, "token": gotify_token},
            "ntfy": {"enabled": ntfy_enabled, "url": ntfy_url, "topic": ntfy_topic, "token": ntfy_token},
            "discord": {"enabled": discord_enabled, "webhook_url": discord_webhook_url},
            "telegram": {"enabled": telegram_enabled, "bot_token": telegram_bot_token, "chat_id": telegram_chat_id},
            "priority": notification_priority,
            "only_on_changes": only_on_changes,
        },
    }

    schedule_keys = [
        "schedule_enabled","frequency","time","day_of_week","day_of_month",
        "prune_containers","prune_images","prune_networks","prune_volumes","prune_build_cache"
    ]
    schedule_changed = any(new_values[k] != old_config.get(k) for k in schedule_keys)
    config.update(new_values)
    if schedule_changed:
        _clear_last_run_key()

    save_config()
    flash("é…ç½®å·²æ›´æ–°ã€‚", "success")
    return redirect(url_for("index"))


@app.route("/run-now", methods=["POST"])
def run_now():
    """ç«‹å³æ‰§è¡Œæ¸…ç†"""
    load_config(silent=True)
    log("æ‰‹åŠ¨æ¸…ç†è§¦å‘å·²æ”¶åˆ°ã€‚")
    ran = run_prune_job(origin="manual", wait=True)
    flash("æ‰‹åŠ¨æ¸…ç†å·²æ‰§è¡Œã€‚" if ran else "æ¸…ç†ä»»åŠ¡è·³è¿‡ï¼ˆå¿™æˆ–è¶…æ—¶ï¼‰ã€‚", "info")
    return redirect(url_for("index"))


@app.route("/preview-prune", methods=["POST"])
def preview_prune():
    """è·å–æ¸…ç†é¢„è§ˆ"""
    load_config(silent=True)
    
    try:
        data = request.get_json() or {}
        if any(k in data for k in ["prune_containers", "prune_images", "prune_networks", "prune_volumes", "prune_build_cache"]):
            config["prune_containers"] = data.get("prune_containers", False)
            config["prune_images"] = data.get("prune_images", False)
            config["prune_networks"] = data.get("prune_networks", False)
            config["prune_volumes"] = data.get("prune_volumes", False)
            config["prune_build_cache"] = data.get("prune_build_cache", False)
            save_config()
            log("æ¸…ç†é¢„è§ˆè¯·æ±‚å·²æ”¶åˆ°å¹¶ä¿å­˜æ›´æ–°åçš„é…ç½®ã€‚")
    except Exception as e:
        log(f"è§£ææ¸…ç†é¢„è§ˆè¯·æ±‚ä½“æ—¶å‡ºé”™: {e}")
    
    log("æ¸…ç†é¢„è§ˆè¯·æ±‚å·²æ”¶åˆ°ã€‚")
    preview = get_prune_preview()
    return jsonify(preview)


@app.route("/run-confirmed", methods=["POST"])
def run_confirmed():
    """ç¡®è®¤åæ‰§è¡Œæ¸…ç†"""
    load_config(silent=True)
    
    try:
        data = request.get_json() or {}
        if any(k in data for k in ["prune_containers", "prune_images", "prune_networks", "prune_volumes", "prune_build_cache"]):
            config["prune_containers"] = data.get("prune_containers", False)
            config["prune_images"] = data.get("prune_images", False)
            config["prune_networks"] = data.get("prune_networks", False)
            config["prune_volumes"] = data.get("prune_volumes", False)
            config["prune_build_cache"] = data.get("prune_build_cache", False)
            save_config()
            log("ç¡®è®¤æ¸…ç†è§¦å‘å·²æ”¶åˆ°å¹¶ä¿å­˜æ›´æ–°åçš„é…ç½®ã€‚")
    except Exception as e:
        log(f"è§£æç¡®è®¤æ¸…ç†è¯·æ±‚ä½“æ—¶å‡ºé”™: {e}")
    
    log("ç¡®è®¤æ‰‹åŠ¨æ¸…ç†è§¦å‘å·²æ”¶åˆ°ã€‚")
    ran = run_prune_job(origin="manual", wait=True)
    return jsonify({
        "success": ran,
        "message": "æ¸…ç†ä»»åŠ¡å·²æˆåŠŸæ‰§è¡Œã€‚" if ran else "æ¸…ç†ä»»åŠ¡è·³è¿‡ï¼ˆå¿™æˆ–è¶…æ—¶ï¼‰ã€‚"
    })


@app.route("/test-notification", methods=["POST"])
def test_notification():
    """å‘é€æµ‹è¯•é€šçŸ¥"""
    load_config(silent=True)
    old_config = json.loads(json.dumps(config))

    frequency = request.form.get("frequency", "daily")
    
    if use_24h_format:
        time_value = request.form.get("time", "03:00")
    else:
        try:
            hour_12 = int(request.form.get("time_hour", "3"))
            minute = int(request.form.get("time_minute", "0"))
            period = request.form.get("time_period", "AM")
            
            hour_12 = max(1, min(12, hour_12))
            minute = max(0, min(59, minute))
            
            if period == "AM":
                hour_24 = 0 if hour_12 == 12 else hour_12
            else:
                hour_24 = 12 if hour_12 == 12 else hour_12 + 12
            
            time_value = f"{hour_24:02d}:{minute:02d}"
        except Exception:
            time_value = "03:00"
    
    day_of_week = request.form.get("day_of_week", "mon")
    raw_dom = request.form.get("day_of_month", "1")
    try:
        day_of_month = int(raw_dom)
    except Exception:
        day_of_month = 1
    day_of_month = max(1, min(31, day_of_month))

    prune_containers = "prune_containers" in request.form
    prune_images = "prune_images" in request.form
    prune_networks = "prune_networks" in request.form
    prune_volumes = "prune_volumes" in request.form
    prune_build_cache = "prune_build_cache" in request.form

    provider = request.form.get("notifications_provider", "gotify")
    gotify_enabled = "gotify_enabled" in request.form
    gotify_url = (request.form.get("gotify_url") or "").strip()
    gotify_token = (request.form.get("gotify_token") or "").strip()
    ntfy_enabled = "ntfy_enabled" in request.form
    ntfy_url = (request.form.get("ntfy_url") or "").strip()
    ntfy_topic = (request.form.get("ntfy_topic") or "").strip()
    ntfy_token = (request.form.get("ntfy_token") or "").strip()
    discord_enabled = "discord_enabled" in request.form
    discord_webhook_url = (request.form.get("discord_webhook_url") or "").strip()
    telegram_enabled = "telegram_enabled" in request.form
    telegram_bot_token = (request.form.get("telegram_bot_token") or "").strip()
    telegram_chat_id = (request.form.get("telegram_chat_id") or "").strip()
    notification_priority = request.form.get("notification_priority", "medium").strip().lower()
    if notification_priority not in ["low", "medium", "high"]:
        notification_priority = "medium"
    only_on_changes = "notifications_only_on_changes" in request.form

    if provider == "gotify" and not gotify_enabled and gotify_url and gotify_token:
        gotify_enabled = True
    if provider == "ntfy" and not ntfy_enabled and ntfy_url and ntfy_topic:
        ntfy_enabled = True
    if provider == "discord" and not discord_enabled and discord_webhook_url:
        discord_enabled = True
    if provider == "telegram" and not telegram_enabled and telegram_bot_token and telegram_chat_id:
        telegram_enabled = True

    time_value = validate_time(time_value)

    new_values = {
        "frequency": frequency,
        "time": time_value,
        "day_of_week": day_of_week,
        "day_of_month": day_of_month,
        "prune_containers": prune_containers,
        "prune_images": prune_images,
        "prune_networks": prune_networks,
        "prune_volumes": prune_volumes,
        "prune_build_cache": prune_build_cache,
        "notifications": {
            "provider": provider,
            "gotify": {"enabled": gotify_enabled, "url": gotify_url, "token": gotify_token},
            "ntfy": {"enabled": ntfy_enabled, "url": ntfy_url, "topic": ntfy_topic, "token": ntfy_token},
            "discord": {"enabled": discord_enabled, "webhook_url": discord_webhook_url},
            "telegram": {"enabled": telegram_enabled, "bot_token": telegram_bot_token, "chat_id": telegram_chat_id},
            "priority": notification_priority,
            "only_on_changes": only_on_changes,
        },
    }

    schedule_keys = [
        "frequency","time","day_of_week","day_of_month",
        "prune_containers","prune_images","prune_networks","prune_volumes","prune_build_cache"
    ]
    schedule_changed = any(new_values[k] != old_config.get(k) for k in schedule_keys)
    config.update(new_values)
    if schedule_changed:
        _clear_last_run_key()

    save_config()
    
    log("ä»UIè¯·æ±‚é€šçŸ¥æµ‹è¯•ã€‚")
    test_priority = config.get("notifications", {}).get("priority", "medium")
    ok = send_notification(
        "PruneMate æµ‹è¯•é€šçŸ¥",
        "è¿™æ˜¯æ¥è‡ª PruneMate çš„æµ‹è¯•æ¶ˆæ¯ã€‚\n\nå¦‚æœæ‚¨çœ‹åˆ°æ­¤æ¶ˆæ¯ï¼Œè¯´æ˜æ‚¨çš„é€šçŸ¥æä¾›å•†é…ç½®å·¥ä½œæ­£å¸¸ã€‚",
        priority=test_priority,
    )
    flash("é…ç½®å·²ä¿å­˜ã€‚ " + ("æµ‹è¯•é€šçŸ¥å·²å‘é€ã€‚" if ok else "æµ‹è¯•é€šçŸ¥å‘é€å¤±è´¥ï¼ˆè¯·æ£€æŸ¥è®¾ç½®å’Œæ—¥å¿—ï¼‰ã€‚"), "info")
    return redirect(url_for("index"))


@app.route("/stats")
def stats():
    """è¿”å›å†å²ç»Ÿè®¡æ•°æ®"""
    return jsonify(load_stats())


@app.route("/api/stats")
def api_stats():
    """è¿”å›æ ¼å¼åŒ–çš„ç»Ÿè®¡æ•°æ®"""
    stats = load_stats()
    
    last_run_text = "ä»æœª"
    last_run_timestamp = None
    if stats.get("last_run"):
        try:
            last_run_dt = datetime.datetime.fromisoformat(stats["last_run"])
            now = datetime.datetime.now(app_timezone)
            
            if last_run_dt.tzinfo is None:
                last_run_dt = last_run_dt.replace(tzinfo=app_timezone)
            
            delta = now - last_run_dt
            
            if delta.days > 0:
                last_run_text = f"{delta.days}å¤©å‰"
            elif delta.seconds >= 3600:
                hours = delta.seconds // 3600
                last_run_text = f"{hours}å°æ—¶å‰"
            elif delta.seconds >= 60:
                minutes = delta.seconds // 60
                last_run_text = f"{minutes}åˆ†é’Ÿå‰"
            else:
                last_run_text = "åˆšåˆš"
            
            last_run_timestamp = int(last_run_dt.timestamp())
        except (ValueError, TypeError, OSError) as e:
            log(f"è§£æä¸Šæ¬¡è¿è¡Œæ—¶é—´æˆ³æ—¶å‡ºé”™: {e}")
            last_run_text = "æœªçŸ¥"
        except Exception as e:
            log(f"/api/stats æ—¶é—´æˆ³è®¡ç®—ä¸­å‡ºç°æ„å¤–é”™è¯¯: {e}")
            last_run_text = "æœªçŸ¥"
    
    return jsonify({
        "pruneRuns": stats.get("prune_runs", 0),
        "containersDeleted": stats.get("containers_deleted", 0),
        "imagesDeleted": stats.get("images_deleted", 0),
        "networksDeleted": stats.get("networks_deleted", 0),
        "volumesDeleted": stats.get("volumes_deleted", 0),
        "buildCacheDeleted": stats.get("build_cache_deleted", 0),
        "spaceReclaimed": stats.get("total_space_reclaimed", 0),
        "spaceReclaimedHuman": human_bytes(stats.get("total_space_reclaimed", 0)),
        "firstRun": stats.get("first_run"),
        "lastRun": stats.get("last_run"),
        "lastRunText": last_run_text,
        "lastRunTimestamp": last_run_timestamp
    })


@app.route("/hosts")
def list_hosts():
    """è¿”å›Dockerä¸»æœºåˆ—è¡¨"""
    load_config(silent=True)
    external_hosts = config.get("docker_hosts", [])
    
    all_hosts = [
        {"name": "æœ¬åœ°", "url": "unix:///var/run/docker.sock", "enabled": True}
    ] + external_hosts
    
    return jsonify({"hosts": all_hosts})


@app.route("/hosts/add", methods=["POST"])
def add_host():
    """æ·»åŠ æ–°çš„Dockerä¸»æœº"""
    load_config(silent=True)
    
    name = (request.form.get("name") or "").strip()
    url = (request.form.get("url") or "").strip()
    enabled = "enabled" in request.form
    
    if not name or not url:
        flash("ä¸»æœºåç§°å’ŒURLæ˜¯å¿…å¡«é¡¹ã€‚", "warn")
        return redirect(url_for("index"))
    
    valid_protocols = ["tcp://", "http://", "https://"]
    if not any(url.startswith(proto) for proto in valid_protocols):
        flash("URLå¿…é¡»ä»¥ tcp://, http://, æˆ– https:// å¼€å¤´", "warn")
        return redirect(url_for("index"))
    
    new_host = {
        "name": name,
        "url": url,
        "enabled": enabled
    }
    
    if "docker_hosts" not in config:
        config["docker_hosts"] = []
    
    config["docker_hosts"].append(new_host)
    save_config()
    
    flash(f"Dockerä¸»æœº '{name}' æ·»åŠ æˆåŠŸã€‚", "info")
    return redirect(url_for("index"))


@app.route("/hosts/<int:index>/update", methods=["POST"])
def update_host(index):
    """æ›´æ–°ç°æœ‰çš„Dockerä¸»æœº"""
    load_config(silent=True)
    
    hosts = config.get("docker_hosts", [])
    if index < 0 or index >= len(hosts):
        flash("æ— æ•ˆçš„ä¸»æœºç´¢å¼•ã€‚", "warn")
        return redirect(url_for("index"))
    
    name = (request.form.get("name") or "").strip()
    url = (request.form.get("url") or "").strip()
    enabled = "enabled" in request.form
    
    if not name or not url:
        flash("ä¸»æœºåç§°å’ŒURLæ˜¯å¿…å¡«é¡¹ã€‚", "warn")
        return redirect(url_for("index"))
    
    valid_protocols = ["tcp://", "http://", "https://"]
    if not any(url.startswith(proto) for proto in valid_protocols):
        flash("URLå¿…é¡»ä»¥ tcp://, http://, æˆ– https:// å¼€å¤´", "warn")
        return redirect(url_for("index"))
    
    hosts[index] = {
        "name": name,
        "url": url,
        "enabled": enabled
    }
    
    config["docker_hosts"] = hosts
    save_config()
    
    flash(f"Dockerä¸»æœº '{name}' æ›´æ–°æˆåŠŸã€‚", "info")
    return redirect(url_for("index"))


@app.route("/hosts/<int:index>/delete", methods=["POST"])
def delete_host(index):
    """åˆ é™¤Dockerä¸»æœº"""
    load_config(silent=True)
    
    hosts = config.get("docker_hosts", [])
    if index < 0 or index >= len(hosts):
        flash("æ— æ•ˆçš„ä¸»æœºç´¢å¼•ã€‚", "warn")
        return redirect(url_for("index"))
    
    deleted_name = hosts[index].get("name", "æœªçŸ¥")
    del hosts[index]
    
    config["docker_hosts"] = hosts
    save_config()
    
    flash(f"Dockerä¸»æœº '{deleted_name}' åˆ é™¤æˆåŠŸã€‚", "info")
    return redirect(url_for("index"))


@app.route("/hosts/<int:index>/toggle", methods=["POST"])
def toggle_host(index):
    """åˆ‡æ¢Dockerä¸»æœºçš„å¯ç”¨/ç¦ç”¨çŠ¶æ€"""
    load_config(silent=True)
    
    hosts = config.get("docker_hosts", [])
    if index < 0 or index >= len(hosts):
        return jsonify({"success": False, "error": "æ— æ•ˆçš„ä¸»æœºç´¢å¼•"}), 400
    
    hosts[index]["enabled"] = not hosts[index].get("enabled", True)
    config["docker_hosts"] = hosts
    save_config()
    
    status = "å·²å¯ç”¨" if hosts[index]["enabled"] else "å·²ç¦ç”¨"
    return jsonify({"success": True, "enabled": hosts[index]["enabled"], "message": f"ä¸»æœºå·²{status}"})


class StandaloneApplication(BaseApplication):
    """è‡ªå®šä¹‰Gunicornåº”ç”¨"""
    
    def __init__(self, app, options=None):
        """åˆå§‹åŒ–Gunicornåº”ç”¨"""
        self.options = options or {}
        self.application = app
        super().__init__()

    def load_config(self):
        """åŠ è½½Gunicorné…ç½®"""
        for key, value in self.options.items():
            if key in self.cfg.settings and value is not None:
                self.cfg.set(key.lower(), value)

    def load(self):
        """è¿”å›Flaskåº”ç”¨å®ä¾‹"""
        return self.application


if __name__ == "__main__":
    load_config()
    scheduler.add_job(heartbeat, CronTrigger(second=0), id="heartbeat", max_instances=1, coalesce=True)
    log("è°ƒåº¦å™¨å¿ƒè·³ä»»åŠ¡å·²å¯åŠ¨ï¼ˆæ¯åˆ†é’Ÿåœ¨:00 æ‰§è¡Œï¼‰ã€‚")
    
    options = {
        "bind": "0.0.0.0:8080",
        "workers": 1,
        "threads": 2,
        "timeout": 120,
        "accesslog": None,
        "errorlog": "-",
        "loglevel": "info",
    }
    StandaloneApplication(app, options).run()